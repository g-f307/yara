"""
QIIME 2 Parser Module
=====================

M√≥dulo para ler e processar arquivos do QIIME 2
Suporta: .qzv, .qza, .tsv, .biom

Autor: Projeto YARA - IFAM
Data: Outubro 2025
"""

import pandas as pd
import numpy as np
import zipfile
import json
import tempfile
import shutil
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import warnings

warnings.filterwarnings('ignore')


class QIIME2Parser:
    """
    Parser principal para arquivos QIIME 2
    """
    
    def __init__(self, base_path: str = "data/qiime2"):
        """
        Inicializa parser
        
        Args:
            base_path: Caminho para diret√≥rio de dados
        """
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)
        self.temp_dir = None
        
    def extract_qzv(self, qzv_path: str) -> Path:
        """
        Extrai conte√∫do de arquivo .qzv
        
        Args:
            qzv_path: Caminho para arquivo .qzv
            
        Returns:
            Path do diret√≥rio extra√≠do
        """
        qzv_path = Path(qzv_path)
        
        if not qzv_path.exists():
            raise FileNotFoundError(f"Arquivo n√£o encontrado: {qzv_path}")
        
        # Criar diret√≥rio tempor√°rio
        self.temp_dir = tempfile.mkdtemp(prefix="qiime2_")
        
        # Extrair
        with zipfile.ZipFile(qzv_path, 'r') as zip_ref:
            zip_ref.extractall(self.temp_dir)
        
        return Path(self.temp_dir)
    
    def find_data_files(self, extract_path: Path, pattern: str = "*.tsv") -> List[Path]:
        """
        Encontra arquivos de dados no diret√≥rio extra√≠do
        
        Args:
            extract_path: Diret√≥rio extra√≠do
            pattern: Padr√£o de arquivo a buscar
            
        Returns:
            Lista de paths encontrados
        """
        files = list(extract_path.rglob(pattern))
        return files
    
    def load_alpha_diversity(self, filepath: str) -> pd.DataFrame:
        """
        Carrega arquivo TSV de diversidade alfa
        
        Args:
            filepath: Caminho para arquivo
            
        Returns:
            DataFrame com m√©tricas de diversidade alfa
        """
        df = pd.read_csv(filepath, sep='\t', index_col=0)
        return df
    
    def load_distance_matrix(self, filepath: str) -> Tuple[pd.DataFrame, List[str]]:
        """
        Carrega matriz de dist√¢ncias
        
        Args:
            filepath: Caminho para arquivo
            
        Returns:
            (DataFrame da matriz, lista de sample IDs)
        """
        df = pd.read_csv(filepath, sep='\t', index_col=0)
        sample_ids = list(df.index)
        return df, sample_ids
    
    def load_taxonomy(self, filepath: str) -> pd.DataFrame:
        """
        Carrega classifica√ß√£o taxon√¥mica
        
        Args:
            filepath: Caminho para arquivo
            
        Returns:
            DataFrame com taxonomia
        """
        df = pd.read_csv(filepath, sep='\t')
        
        # Parse taxonomia se estiver em formato string
        if 'Taxon' in df.columns:
            df['Taxonomy_Parsed'] = df['Taxon'].apply(self._parse_taxonomy_string)
        
        return df
    
    def _parse_taxonomy_string(self, tax_string: str) -> Dict[str, str]:
        """
        Parse string de taxonomia do QIIME 2
        
        Args:
            tax_string: String de taxonomia (ex: "k__Bacteria; p__Proteobacteria")
            
        Returns:
            Dicion√°rio com n√≠veis taxon√¥micos
        """
        levels = {
            'k': 'Kingdom',
            'p': 'Phylum',
            'c': 'Class',
            'o': 'Order',
            'f': 'Family',
            'g': 'Genus',
            's': 'Species'
        }
        
        parsed = {}
        
        if pd.isna(tax_string):
            return parsed
        
        parts = tax_string.split(';')
        
        for part in parts:
            part = part.strip()
            if '__' in part:
                level_code, taxon = part.split('__', 1)
                level_code = level_code.strip()
                taxon = taxon.strip()
                
                if level_code in levels:
                    parsed[levels[level_code]] = taxon if taxon else 'Unassigned'
        
        return parsed
    
    def load_feature_table(self, filepath: str) -> pd.DataFrame:
        """
        Carrega tabela de features (OTU/ASV table)
        
        Args:
            filepath: Caminho para arquivo
            
        Returns:
            DataFrame com abund√¢ncias
        """
        # Tentar ler como TSV normal
        try:
            df = pd.read_csv(filepath, sep='\t', index_col=0, comment='#')
            return df
        except Exception as e:
            print(f"Erro ao ler tabela: {e}")
            return None
    
    def calculate_alpha_diversity_stats(self, df: pd.DataFrame, 
                                       group_column: Optional[str] = None) -> Dict:
        """
        Calcula estat√≠sticas de diversidade alfa
        
        Args:
            df: DataFrame com m√©tricas de diversidade
            group_column: Nome da coluna de grupos (opcional)
            
        Returns:
            Dicion√°rio com estat√≠sticas
        """
        stats = {
            'overall': df.describe().to_dict(),
            'metrics': list(df.columns)
        }
        
        if group_column and group_column in df.columns:
            stats['by_group'] = {}
            for group in df[group_column].unique():
                subset = df[df[group_column] == group]
                stats['by_group'][group] = subset.describe().to_dict()
        
        return stats
    
    def get_top_taxa(self, taxonomy_df: pd.DataFrame, 
                     abundance_df: Optional[pd.DataFrame] = None,
                     level: str = 'Phylum',
                     top_n: int = 10) -> pd.DataFrame:
        """
        Obt√©m top N t√°xons mais abundantes
        
        Args:
            taxonomy_df: DataFrame com taxonomia
            abundance_df: DataFrame com abund√¢ncias (opcional)
            level: N√≠vel taxon√¥mico
            top_n: N√∫mero de t√°xons
            
        Returns:
            DataFrame com top t√°xons
        """
        if abundance_df is not None:
            # Calcular abund√¢ncia total por t√°xon
            total_abundance = abundance_df.sum(axis=0)
            taxonomy_df = taxonomy_df.copy()
            taxonomy_df['Total_Abundance'] = taxonomy_df.index.map(total_abundance)
            taxonomy_df = taxonomy_df.sort_values('Total_Abundance', ascending=False)
        
        return taxonomy_df.head(top_n)
    
    def cleanup(self):
        """Remove arquivos tempor√°rios"""
        if self.temp_dir and Path(self.temp_dir).exists():
            shutil.rmtree(self.temp_dir)
            self.temp_dir = None


class AlphaDiversityAnalyzer:
    """
    Analisador espec√≠fico para diversidade alfa
    """
    
    def __init__(self, data: pd.DataFrame):
        """
        Args:
            data: DataFrame com m√©tricas de diversidade alfa
        """
        self.data = data
    
    def get_summary_stats(self, metric: str = 'shannon') -> Dict:
        """
        Estat√≠sticas resumidas para uma m√©trica
        
        Args:
            metric: Nome da m√©trica
            
        Returns:
            Dicion√°rio com estat√≠sticas
        """
        if metric not in self.data.columns:
            available = list(self.data.columns)
            raise ValueError(f"M√©trica '{metric}' n√£o encontrada. Dispon√≠veis: {available}")
        
        serie = self.data[metric]
        
        return {
            'mean': float(serie.mean()),
            'median': float(serie.median()),
            'std': float(serie.std()),
            'min': float(serie.min()),
            'max': float(serie.max()),
            'q25': float(serie.quantile(0.25)),
            'q75': float(serie.quantile(0.75))
        }
    
    def interpret_value(self, value: float, metric: str = 'shannon') -> str:
        """
        Interpreta um valor de diversidade
        
        Args:
            value: Valor da m√©trica
            metric: Tipo de m√©trica
            
        Returns:
            String com interpreta√ß√£o
        """
        metric = metric.lower()
        
        if 'shannon' in metric:
            if value < 1.5:
                return "Baixa diversidade - comunidade dominada por poucas esp√©cies"
            elif value < 2.5:
                return "Diversidade moderada - comunidade relativamente equilibrada"
            elif value < 3.5:
                return "Alta diversidade - comunidade bem equilibrada"
            else:
                return "Diversidade muito alta - comunidade muito complexa"
        
        elif 'simpson' in metric:
            if value < 0.5:
                return "Baixa diversidade - alta domin√¢ncia de poucas esp√©cies"
            elif value < 0.8:
                return "Diversidade moderada"
            else:
                return "Alta diversidade - baixa domin√¢ncia"
        
        elif 'observed' in metric.lower() or 'richness' in metric.lower():
            if value < 100:
                return "Baixa riqueza - poucas esp√©cies detectadas"
            elif value < 300:
                return "Riqueza moderada"
            else:
                return "Alta riqueza - muitas esp√©cies detectadas"
        
        return "Interpreta√ß√£o n√£o dispon√≠vel para esta m√©trica"
    
    def compare_groups(self, group_column: str, metric: str = 'shannon') -> Dict:
        """
        Compara m√©trica entre grupos
        
        Args:
            group_column: Nome da coluna de grupos
            metric: M√©trica a comparar
            
        Returns:
            Dicion√°rio com compara√ß√£o
        """
        from scipy.stats import mannwhitneyu
        
        if group_column not in self.data.columns:
            raise ValueError(f"Coluna '{group_column}' n√£o encontrada")
        
        groups = self.data[group_column].unique()
        
        if len(groups) != 2:
            return {'error': 'Compara√ß√£o suporta apenas 2 grupos'}
        
        group1_data = self.data[self.data[group_column] == groups[0]][metric]
        group2_data = self.data[self.data[group_column] == groups[1]][metric]
        
        stat, pvalue = mannwhitneyu(group1_data, group2_data)
        
        return {
            'groups': list(groups),
            'group1_mean': float(group1_data.mean()),
            'group2_mean': float(group2_data.mean()),
            'difference_pct': float(((group2_data.mean() - group1_data.mean()) / group1_data.mean()) * 100),
            'statistic': float(stat),
            'p_value': float(pvalue),
            'significant': pvalue < 0.05
        }


class BetaDiversityAnalyzer:
    """
    Analisador espec√≠fico para diversidade beta
    """
    
    def __init__(self, distance_matrix: pd.DataFrame):
        """
        Args:
            distance_matrix: Matriz de dist√¢ncias
        """
        self.distance_matrix = distance_matrix
        self.sample_ids = list(distance_matrix.index)
    
    def get_distance_stats(self) -> Dict:
        """
        Estat√≠sticas gerais das dist√¢ncias
        
        Returns:
            Dicion√°rio com estat√≠sticas
        """
        # Pegar apenas tri√¢ngulo superior (sem diagonal)
        triu_indices = np.triu_indices_from(self.distance_matrix.values, k=1)
        distances = self.distance_matrix.values[triu_indices]
        
        return {
            'mean': float(np.mean(distances)),
            'median': float(np.median(distances)),
            'std': float(np.std(distances)),
            'min': float(np.min(distances)),
            'max': float(np.max(distances))
        }
    
    def calculate_pcoa(self, n_components: int = 2) -> pd.DataFrame:
        """
        Calcula PCoA
        
        Args:
            n_components: N√∫mero de componentes
            
        Returns:
            DataFrame com coordenadas
        """
        from sklearn.manifold import MDS
        
        mds = MDS(
            n_components=n_components,
            dissimilarity='precomputed',
            random_state=42
        )
        
        coords = mds.fit_transform(self.distance_matrix.values)
        
        columns = [f'PC{i+1}' for i in range(n_components)]
        df_coords = pd.DataFrame(
            coords,
            index=self.sample_ids,
            columns=columns
        )
        
        return df_coords
    
    def get_closest_samples(self, sample_id: str, n: int = 5) -> List[Tuple[str, float]]:
        """
        Encontra amostras mais pr√≥ximas
        
        Args:
            sample_id: ID da amostra
            n: N√∫mero de amostras
            
        Returns:
            Lista de (sample_id, dist√¢ncia)
        """
        if sample_id not in self.sample_ids:
            raise ValueError(f"Amostra '{sample_id}' n√£o encontrada")
        
        distances = self.distance_matrix.loc[sample_id]
        distances = distances[distances.index != sample_id]
        closest = distances.nsmallest(n)
        
        return list(zip(closest.index, closest.values))


# Fun√ß√µes auxiliares de conveni√™ncia

def load_qiime2_data(filepath: str, data_type: str = 'auto') -> pd.DataFrame:
    """
    Fun√ß√£o de conveni√™ncia para carregar dados QIIME 2
    
    Args:
        filepath: Caminho para arquivo
        data_type: Tipo de dado ('alpha', 'beta', 'taxonomy', 'auto')
        
    Returns:
        DataFrame com dados
    """
    parser = QIIME2Parser()
    
    filepath = Path(filepath)
    
    # Auto-detectar tipo
    if data_type == 'auto':
        if 'alpha' in filepath.name.lower():
            data_type = 'alpha'
        elif 'distance' in filepath.name.lower() or 'beta' in filepath.name.lower():
            data_type = 'beta'
        elif 'taxonomy' in filepath.name.lower():
            data_type = 'taxonomy'
    
    # Carregar conforme tipo
    if filepath.suffix == '.qzv':
        extract_path = parser.extract_qzv(filepath)
        tsv_files = parser.find_data_files(extract_path)
        if tsv_files:
            df = pd.read_csv(tsv_files[0], sep='\t', index_col=0)
        parser.cleanup()
        return df
    else:
        if data_type == 'alpha':
            return parser.load_alpha_diversity(filepath)
        elif data_type == 'beta':
            df, _ = parser.load_distance_matrix(filepath)
            return df
        elif data_type == 'taxonomy':
            return parser.load_taxonomy(filepath)
        else:
            return pd.read_csv(filepath, sep='\t', index_col=0)


if __name__ == "__main__":
    print("üß¨ QIIME 2 Parser Module")
    print("=" * 60)
    print("M√≥dulo carregado com sucesso!")
    print("\nClasses dispon√≠veis:")
    print("  - QIIME2Parser")
    print("  - AlphaDiversityAnalyzer")
    print("  - BetaDiversityAnalyzer")
    print("\nFun√ß√µes:")
    print("  - load_qiime2_data()")
