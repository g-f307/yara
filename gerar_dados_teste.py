#!/usr/bin/env python3
"""
Gerador de Dados de Teste para YARA
====================================

Gera dados sintÃ©ticos no formato QIIME 2 para testar todas as funcionalidades do YARA.

Autor: Projeto YARA - IFAM
Data: Outubro 2025
"""

import pandas as pd
import numpy as np
from pathlib import Path
import random

# Configurar seed para reprodutibilidade
np.random.seed(42)
random.seed(42)

# DiretÃ³rio de saÃ­da
OUTPUT_DIR = Path("data/qiime2")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

print("ðŸ§¬ YARA - Gerador de Dados de Teste")
print("=" * 60)
print()


# ============================================================================
# 1. GERAR DADOS DE DIVERSIDADE ALFA
# ============================================================================

def gerar_diversidade_alfa(n_samples=15):
    """Gera arquivo de diversidade alfa"""
    print("ðŸ“Š Gerando dados de diversidade alfa...")
    
    sample_ids = [f"amostra_{i:03d}" for i in range(1, n_samples + 1)]
    
    # Gerar mÃ©tricas de diversidade
    data = {
        'Shannon': np.random.uniform(1.5, 4.5, n_samples),
        'Simpson': np.random.uniform(0.6, 0.95, n_samples),
        'Observed_Features': np.random.randint(80, 350, n_samples),
        'Chao1': np.random.uniform(100, 400, n_samples),
        'Faith_PD': np.random.uniform(5, 25, n_samples)
    }
    
    df = pd.DataFrame(data, index=sample_ids)
    df.index.name = 'sample-id'
    
    output_file = OUTPUT_DIR / "diversidade_alfa.tsv"
    df.to_csv(output_file, sep='\t')
    
    print(f"  âœ… Criado: {output_file}")
    print(f"     â€¢ {n_samples} amostras")
    print(f"     â€¢ 5 mÃ©tricas (Shannon, Simpson, Observed_Features, Chao1, Faith_PD)")
    print()
    
    return df


# ============================================================================
# 2. GERAR MATRIZ DE DISTÃ‚NCIAS (DIVERSIDADE BETA)
# ============================================================================

def gerar_matriz_distancias(sample_ids):
    """Gera matriz de distÃ¢ncias Bray-Curtis"""
    print("ðŸ“Š Gerando matriz de distÃ¢ncias (Beta)...")
    
    n = len(sample_ids)
    
    # Gerar matriz simÃ©trica de distÃ¢ncias
    distances = np.random.uniform(0.1, 0.9, (n, n))
    
    # Tornar simÃ©trica
    distances = (distances + distances.T) / 2
    
    # Diagonal = 0
    np.fill_diagonal(distances, 0)
    
    df = pd.DataFrame(distances, index=sample_ids, columns=sample_ids)
    df.index.name = 'sample-id'
    
    output_file = OUTPUT_DIR / "distance_matrix_braycurtis.tsv"
    df.to_csv(output_file, sep='\t')
    
    print(f"  âœ… Criado: {output_file}")
    print(f"     â€¢ Matriz {n}x{n}")
    print(f"     â€¢ MÃ©trica: Bray-Curtis")
    print()
    
    return df


# ============================================================================
# 3. GERAR COORDENADAS PCoA
# ============================================================================

def gerar_pcoa_coordinates(sample_ids):
    """Gera coordenadas PCoA"""
    print("ðŸ“Š Gerando coordenadas PCoA...")
    
    n = len(sample_ids)
    
    # Gerar 3 eixos principais
    data = {
        'PC1': np.random.uniform(-0.5, 0.5, n),
        'PC2': np.random.uniform(-0.4, 0.4, n),
        'PC3': np.random.uniform(-0.3, 0.3, n)
    }
    
    df = pd.DataFrame(data, index=sample_ids)
    df.index.name = 'sample-id'
    
    output_file = OUTPUT_DIR / "pcoa_coordinates.tsv"
    df.to_csv(output_file, sep='\t')
    
    print(f"  âœ… Criado: {output_file}")
    print(f"     â€¢ {n} amostras")
    print(f"     â€¢ 3 componentes principais")
    print()
    
    return df


# ============================================================================
# 4. GERAR TAXONOMIA
# ============================================================================

def gerar_taxonomia(n_features=200):
    """Gera classificaÃ§Ã£o taxonÃ´mica"""
    print("ðŸ¦  Gerando dados de taxonomia...")
    
    # Filos comuns em microbioma
    phyla = [
        'Proteobacteria', 'Firmicutes', 'Bacteroidetes', 'Actinobacteria',
        'Verrucomicrobia', 'Planctomycetes', 'Cyanobacteria', 'Acidobacteria'
    ]
    
    # Classes por filo (simplificado)
    classes = {
        'Proteobacteria': ['Alphaproteobacteria', 'Betaproteobacteria', 'Gammaproteobacteria', 'Deltaproteobacteria'],
        'Firmicutes': ['Bacilli', 'Clostridia', 'Negativicutes'],
        'Bacteroidetes': ['Bacteroidia', 'Flavobacteriia', 'Sphingobacteriia'],
        'Actinobacteria': ['Actinobacteria', 'Coriobacteriia'],
        'Verrucomicrobia': ['Verrucomicrobiae'],
        'Planctomycetes': ['Planctomycetacia'],
        'Cyanobacteria': ['Oxyphotobacteria'],
        'Acidobacteria': ['Acidobacteriia']
    }
    
    # GÃªneros comuns
    genera = [
        'Escherichia', 'Bacillus', 'Bacteroides', 'Streptococcus', 'Lactobacillus',
        'Clostridium', 'Prevotella', 'Akkermansia', 'Faecalibacterium', 'Bifidobacterium',
        'Ruminococcus', 'Roseburia', 'Blautia', 'Coprococcus', 'Dorea'
    ]
    
    feature_ids = [f"ASV_{i:04d}" for i in range(1, n_features + 1)]
    
    taxonomies = []
    confidence_scores = []
    
    for _ in range(n_features):
        # Escolher filo (com distribuiÃ§Ã£o realista)
        phylum = random.choices(
            phyla,
            weights=[30, 25, 20, 10, 5, 4, 3, 3],  # Proteobacteria mais comum
            k=1
        )[0]
        
        # Escolher classe
        class_name = random.choice(classes[phylum])
        
        # Escolher gÃªnero (com chance de nÃ£o classificado)
        if random.random() > 0.3:  # 70% classificado atÃ© gÃªnero
            genus = random.choice(genera)
            taxonomy = f"k__Bacteria; p__{phylum}; c__{class_name}; o__; f__; g__{genus}; s__"
            confidence = random.uniform(0.85, 0.99)
        elif random.random() > 0.5:  # Classificado atÃ© classe
            taxonomy = f"k__Bacteria; p__{phylum}; c__{class_name}; o__; f__; g__; s__"
            confidence = random.uniform(0.70, 0.85)
        else:  # Classificado apenas atÃ© filo
            taxonomy = f"k__Bacteria; p__{phylum}; c__; o__; f__; g__; s__"
            confidence = random.uniform(0.60, 0.75)
        
        taxonomies.append(taxonomy)
        confidence_scores.append(confidence)
    
    df = pd.DataFrame({
        'Feature ID': feature_ids,
        'Taxon': taxonomies,
        'Confidence': confidence_scores
    })
    
    output_file = OUTPUT_DIR / "taxonomy.tsv"
    df.to_csv(output_file, sep='\t', index=False)
    
    print(f"  âœ… Criado: {output_file}")
    print(f"     â€¢ {n_features} features (ASVs)")
    print(f"     â€¢ {len(phyla)} filos diferentes")
    print()
    
    return df


# ============================================================================
# 5. GERAR DADOS DE RAREFAÃ‡ÃƒO
# ============================================================================

def gerar_rarefacao(sample_ids):
    """Gera curvas de rarefaÃ§Ã£o"""
    print("ðŸ“ˆ Gerando dados de rarefaÃ§Ã£o...")
    
    n_samples = len(sample_ids)
    
    # Profundidades de sequenciamento
    depths = [1000, 5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000]
    
    data = {}
    
    for sample_id in sample_ids:
        # ParÃ¢metros da curva para cada amostra
        max_features = random.randint(150, 350)  # MÃ¡ximo de features
        saturation_rate = random.uniform(0.0001, 0.0003)  # Taxa de saturaÃ§Ã£o
        
        curve = []
        for depth in depths:
            # Modelo de saturaÃ§Ã£o: features = max * (1 - e^(-rate * depth))
            features = max_features * (1 - np.exp(-saturation_rate * depth))
            
            # Adicionar ruÃ­do
            features += random.uniform(-5, 5)
            features = max(0, features)  # NÃ£o pode ser negativo
            
            curve.append(features)
        
        data[sample_id] = curve
    
    df = pd.DataFrame(data, index=depths).T
    df.index.name = 'sample-id'
    
    output_file = OUTPUT_DIR / "rarefaction.tsv"
    df.to_csv(output_file, sep='\t')
    
    print(f"  âœ… Criado: {output_file}")
    print(f"     â€¢ {n_samples} amostras")
    print(f"     â€¢ {len(depths)} profundidades ({min(depths)} - {max(depths)})")
    print()
    
    return df


# ============================================================================
# 6. GERAR METADATA
# ============================================================================

def gerar_metadata(sample_ids):
    """Gera arquivo de metadata"""
    print("ðŸ“‹ Gerando metadata...")
    
    n_samples = len(sample_ids)
    
    # Dividir amostras em grupos
    grupos = ['Controle', 'Tratamento_A', 'Tratamento_B']
    locais = ['Floresta', 'Rio', 'Solo']
    
    data = {
        'sample-id': sample_ids,
        'grupo': [random.choice(grupos) for _ in range(n_samples)],
        'local': [random.choice(locais) for _ in range(n_samples)],
        'pH': np.random.uniform(4.5, 7.5, n_samples),
        'temperatura': np.random.uniform(20, 35, n_samples),
        'umidade': np.random.uniform(40, 90, n_samples)
    }
    
    df = pd.DataFrame(data)
    
    output_file = OUTPUT_DIR / "metadata.tsv"
    df.to_csv(output_file, sep='\t', index=False)
    
    print(f"  âœ… Criado: {output_file}")
    print(f"     â€¢ {n_samples} amostras")
    print(f"     â€¢ 3 grupos: {', '.join(grupos)}")
    print(f"     â€¢ 3 locais: {', '.join(locais)}")
    print(f"     â€¢ 3 variÃ¡veis ambientais (pH, temperatura, umidade)")
    print()
    
    return df


# ============================================================================
# 7. GERAR TABELA DE ABUNDÃ‚NCIAS
# ============================================================================

def gerar_tabela_abundancias(sample_ids, n_features=200):
    """Gera tabela de abundÃ¢ncias (feature table)"""
    print("ðŸ“Š Gerando tabela de abundÃ¢ncias...")
    
    feature_ids = [f"ASV_{i:04d}" for i in range(1, n_features + 1)]
    
    # Gerar abundÃ¢ncias com distribuiÃ§Ã£o realista (muitos zeros, alguns valores altos)
    data = {}
    
    for sample_id in sample_ids:
        abundances = []
        for _ in range(n_features):
            # 60% de chance de ser zero (esparsidade)
            if random.random() < 0.6:
                abundances.append(0)
            else:
                # DistribuiÃ§Ã£o log-normal para abundÃ¢ncias
                abundances.append(int(np.random.lognormal(3, 2)))
        
        data[sample_id] = abundances
    
    df = pd.DataFrame(data, index=feature_ids)
    df.index.name = '#OTU ID'
    
    output_file = OUTPUT_DIR / "feature_table.tsv"
    df.to_csv(output_file, sep='\t')
    
    print(f"  âœ… Criado: {output_file}")
    print(f"     â€¢ {n_features} features")
    print(f"     â€¢ {len(sample_ids)} amostras")
    print(f"     â€¢ Matriz esparsa (abundÃ¢ncias)")
    print()
    
    return df


# ============================================================================
# 8. GERAR README
# ============================================================================

def gerar_readme():
    """Gera README explicativo"""
    print("ðŸ“ Gerando README...")
    
    readme_content = """# Dados de Teste QIIME 2 - YARA

## ðŸ“‹ DescriÃ§Ã£o

Este diretÃ³rio contÃ©m **dados sintÃ©ticos** gerados para testar todas as funcionalidades do chatbot YARA.

**âš ï¸ IMPORTANTE:** Estes sÃ£o dados de teste fictÃ­cios, nÃ£o representam anÃ¡lises reais.

## ðŸ“Š Arquivos DisponÃ­veis

### Diversidade Alfa
- **diversidade_alfa.tsv**: MÃ©tricas de diversidade alfa (Shannon, Simpson, etc.)
  - 15 amostras
  - 5 mÃ©tricas diferentes

### Diversidade Beta
- **distance_matrix_braycurtis.tsv**: Matriz de distÃ¢ncias Bray-Curtis
  - Matriz 15x15
  - Valores entre 0 (idÃªnticas) e 1 (totalmente diferentes)

- **pcoa_coordinates.tsv**: Coordenadas PCoA
  - 3 componentes principais (PC1, PC2, PC3)

### Taxonomia
- **taxonomy.tsv**: ClassificaÃ§Ã£o taxonÃ´mica
  - 200 features (ASVs)
  - 8 filos diferentes
  - NÃ­veis: Reino â†’ Filo â†’ Classe â†’ Ordem â†’ FamÃ­lia â†’ GÃªnero â†’ EspÃ©cie

### RarefaÃ§Ã£o
- **rarefaction.tsv**: Curvas de rarefaÃ§Ã£o
  - 15 amostras
  - 11 profundidades (1.000 - 50.000 sequÃªncias)

### AbundÃ¢ncias
- **feature_table.tsv**: Tabela de abundÃ¢ncias
  - 200 features x 15 amostras
  - Matriz esparsa (muitos zeros)

### Metadata
- **metadata.tsv**: InformaÃ§Ãµes das amostras
  - Grupos experimentais (Controle, Tratamento_A, Tratamento_B)
  - Locais de coleta (Floresta, Rio, Solo)
  - VariÃ¡veis ambientais (pH, temperatura, umidade)

## ðŸ§ª Como Usar

### 1. Testar no Chatbot

```bash
cd ~/Documentos/pibic/yara
conda activate yara_rasa

# Treinar modelo
make train

# Terminal 1: Actions
make actions

# Terminal 2: Chat
make shell
```

**Perguntas para testar:**
- "Quais dados tenho disponÃ­veis?"
- "O que Ã© diversidade alfa?"
- "Analisa rarefaÃ§Ã£o"
- "Quais os grupos mais abundantes?"
- "Exporta relatÃ³rio"

### 2. Testar nos Notebooks

```bash
conda activate yara_notebooks
jupyter lab

# Abrir notebooks:
# - notebooks/notebook_exploracao_qiime2.ipynb
# - notebooks/notebook_diversidade_beta.ipynb
# - notebooks/03_analise_rarefacao.ipynb
```

### 3. Usar Programaticamente

```python
import pandas as pd

# Carregar diversidade alfa
df_alpha = pd.read_csv('data/qiime2/diversidade_alfa.tsv', sep='\\t', index_col=0)

# Carregar rarefaÃ§Ã£o
df_rarefaction = pd.read_csv('data/qiime2/rarefaction.tsv', sep='\\t', index_col=0)

# Usar com YARA
from actions.utils.rarefaction_analyzer import RarefactionAnalyzer
analyzer = RarefactionAnalyzer(df_rarefaction)
```

## ðŸ”„ Regenerar Dados

Para gerar novos dados de teste:

```bash
python gerar_dados_teste.py
```

## ðŸ“š ReferÃªncias

- [QIIME 2 Documentation](https://docs.qiime2.org/)
- [QIIME 2 Tutorials](https://docs.qiime2.org/2024.10/tutorials/)

---

**Gerado por:** YARA - Your Assistant for Results Analysis  
**Projeto:** IFAM - EMBRAPA - INPA  
**Data:** Outubro 2025
"""
    
    output_file = OUTPUT_DIR / "README.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"  âœ… Criado: {output_file}")
    print()


# ============================================================================
# MAIN
# ============================================================================

def main():
    """FunÃ§Ã£o principal"""
    
    # 1. Diversidade Alfa
    df_alpha = gerar_diversidade_alfa(n_samples=15)
    sample_ids = list(df_alpha.index)
    
    # 2. Diversidade Beta
    gerar_matriz_distancias(sample_ids)
    gerar_pcoa_coordinates(sample_ids)
    
    # 3. Taxonomia
    gerar_taxonomia(n_features=200)
    
    # 4. RarefaÃ§Ã£o
    gerar_rarefacao(sample_ids)
    
    # 5. Metadata
    gerar_metadata(sample_ids)
    
    # 6. Tabela de AbundÃ¢ncias
    gerar_tabela_abundancias(sample_ids, n_features=200)
    
    # 7. README
    gerar_readme()
    
    # Resumo final
    print("=" * 60)
    print("âœ… GERAÃ‡ÃƒO CONCLUÃDA COM SUCESSO!")
    print("=" * 60)
    print()
    print(f"ðŸ“ DiretÃ³rio: {OUTPUT_DIR.absolute()}")
    print()
    print("ðŸ“Š Arquivos criados:")
    files = sorted(OUTPUT_DIR.glob("*"))
    for f in files:
        size = f.stat().st_size / 1024  # KB
        print(f"  â€¢ {f.name:<35} ({size:>6.1f} KB)")
    
    print()
    print("ðŸš€ PrÃ³ximos passos:")
    print("  1. Treinar modelo: make train")
    print("  2. Testar chatbot: make shell")
    print("  3. Abrir notebooks: jupyter lab")
    print()
    print("ðŸ’¡ Leia data/qiime2/README.md para mais informaÃ§Ãµes!")
    print()


if __name__ == "__main__":
    main()
